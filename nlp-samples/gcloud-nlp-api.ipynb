{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Natural Language API\n",
    "\n",
    "- [Natural Language API Client Libraries](https://cloud.google.com/natural-language/docs/reference/libraries#client-libraries-usage-python)\n",
    "- [Google Cloud Natural Language API Python Samples](https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/language/cloud-client/v1)\n",
    "\n",
    "First, authenticate by running the following command in an interactive terminal:\n",
    "```\n",
    "gcloud auth application-default login\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from google.cloud import language\n",
    "from google.cloud import storage as gcs\n",
    "import six\n",
    "import os\n",
    "from tempfile import NamedTemporaryFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = \"\"\"Hello, world!\n",
    "President Obama is speaking at the White House.\n",
    "Ladies and gentlemen!\n",
    "世界、こんにちは！\n",
    "今日は天気いいですね！\n",
    "悲しいニュースですね\n",
    "素晴らしい\n",
    "Google Cloud Natural Language API は、使いやすい REST API を介して強力な機械学習モデルを提供することで、テキストの構造と意味を解析できるようにします。この API を使用すれば、ドキュメント、ニュース記事、ブログ記事に含まれる人、場所、イベントなどに関する情報を抽出できるようになります。ソーシャル メディア上のコメントから商品に対するセンチメント（感情）を把握したり、コールセンターやメッセージ アプリに寄せられた消費者の意見から顧客満足度を分析したりすることができます。リクエストでアップロードしたテキストを分析することも、Google Cloud Storage のドキュメント ストレージ上のデータを分析することもできます。\"\"\"\n",
    "\n",
    "# Specify some gcs_uri that you have read access to       \n",
    "gcs_uri = 'gs://qa-nlp-1.appspot.com/messages/-KoD6Ht5pST_rdxZTXkZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob messages/-KoD6Ht5pST_rdxZTXkZ downloaded to /tmp/tmpur9praxv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ＡＩの経済効果、2030年までに1780兆円規模'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://cloud.google.com/storage/docs/reference/libraries\n",
    "# https://github.com/GoogleCloudPlatform/python-docs-samples/blob/85d4b1c52de3b8749c139c63bd9f37fdd85da4c8/storage/cloud-client/snippets.py\n",
    "def read_gcs(bucket_name, source_blob_name):\n",
    "  gcs = storage.Client()\n",
    "  bucket = gcs.get_bucket(bucket_name)\n",
    "  f = NamedTemporaryFile()\n",
    "  blob = bucket.blob(source_blob_name)\n",
    "  blob.download_to_filename(f.name)\n",
    "  print('Blob {} downloaded to {}.'.format(\n",
    "      source_blob_name,\n",
    "      f.name))\n",
    "  text = f.read()\n",
    "  f.close()\n",
    "  return decode_utf(text)\n",
    "#\n",
    "read_gcs('qa-nlp-1.appspot.com', 'messages/-KoD6Ht5pST_rdxZTXkZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_utf(text):\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "    return text\n",
    "\n",
    "  \n",
    "def doc_from_text(text):\n",
    "    text = decode_utf(text)\n",
    "    return language_client.document_from_text(text)\n",
    "\n",
    "  \n",
    "def doc_from_gcs(gcs_uri):\n",
    "    return language_client.document_from_url(gcs_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://github.com/GoogleCloudPlatform/python-docs-samples/blob/master/language/cloud-client/v1/snippets.py\n",
    "language_client = language.Client()\n",
    "\n",
    "def sentiment_text(text):\n",
    "    \"\"\"Detects sentiment in the text.\"\"\"\n",
    "    document = doc_from_text(text)\n",
    "\n",
    "    # Detects sentiment in the document. You can also analyze HTML with:\n",
    "    #   document.doc_type == language.Document.HTML\n",
    "    sentiment = document.analyze_sentiment().sentiment\n",
    "    \n",
    "    print('Score: {}'.format(sentiment.score))\n",
    "    print('Magnitude: {}'.format(sentiment.magnitude))\n",
    "\n",
    "\n",
    "def sentiment_gcs(gcs_uri):\n",
    "    \"\"\"Detects sentiment in the file located in Google Cloud Storage.\"\"\"\n",
    "    document = doc_from_gcs(gcs_uri)\n",
    "\n",
    "    # Detects sentiment in the document. You can also analyze HTML with:\n",
    "    #   document.doc_type == language.Document.HTML\n",
    "    sentiment = document.analyze_sentiment().sentiment\n",
    "\n",
    "    print('Score: {}'.format(sentiment.score))\n",
    "    print('Magnitude: {}'.format(sentiment.magnitude))\n",
    "\n",
    "\n",
    "def entities_text(text):\n",
    "    \"\"\"Detects entities in the text.\"\"\"\n",
    "    document = doc_from_text(text)\n",
    "\n",
    "    # Detects entities in the document. You can also analyze HTML with:\n",
    "    #   document.doc_type == language.Document.HTML\n",
    "    entities = document.analyze_entities().entities\n",
    "\n",
    "    for entity in entities:\n",
    "        print('=' * 20)\n",
    "        print(u'{:<16}: {}'.format('name', entity.name))\n",
    "        print(u'{:<16}: {}'.format('type', entity.entity_type))\n",
    "        print(u'{:<16}: {}'.format('metadata', entity.metadata))\n",
    "        print(u'{:<16}: {}'.format('salience', entity.salience))\n",
    "        print(u'{:<16}: {}'.format('wikipedia_url',\n",
    "              entity.metadata.get('wikipedia_url', '-')))\n",
    "\n",
    "\n",
    "def entities_gcs(gcs_uri):\n",
    "    \"\"\"Detects entities in the file located in Google Cloud Storage.\"\"\"\n",
    "    document = doc_from_gcs(gcs_uri)\n",
    "\n",
    "\n",
    "    # Detects sentiment in the document. You can also analyze HTML with:\n",
    "    #   document.doc_type == language.Document.HTML\n",
    "    entities = document.analyze_entities().entities\n",
    "\n",
    "    for entity in entities:\n",
    "        print('=' * 20)\n",
    "        print(u'{:<16}: {}'.format('name', entity.name))\n",
    "        print(u'{:<16}: {}'.format('type', entity.entity_type))\n",
    "        print(u'{:<16}: {}'.format('metadata', entity.metadata))\n",
    "        print(u'{:<16}: {}'.format('salience', entity.salience))\n",
    "        print(u'{:<16}: {}'.format('wikipedia_url',\n",
    "              entity.metadata.get('wikipedia_url', '-')))\n",
    "\n",
    "\n",
    "def syntax_text(text):\n",
    "    \"\"\"Detects syntax in the text.\"\"\"\n",
    "    document = doc_from_text(text)\n",
    "\n",
    "    # Detects syntax in the document. You can also analyze HTML with:\n",
    "    #   document.doc_type == language.Document.HTML\n",
    "    tokens = document.analyze_syntax().tokens\n",
    "\n",
    "    for token in tokens:\n",
    "        print(u'{}: {}'.format(token.part_of_speech.tag, token.text_content))\n",
    "\n",
    "def syntax_gcs(gcs_uri):\n",
    "    \"\"\"Detects syntax in the file located in Google Cloud Storage.\"\"\"\n",
    "    document = doc_from_gcs(gcs_uri)\n",
    "\n",
    "    # Detects syntax in the document. You can also analyze HTML with:\n",
    "    #   document.doc_type == language.Document.HTML\n",
    "    tokens = document.analyze_syntax().tokens\n",
    "\n",
    "    for token in tokens:\n",
    "        print(u'{}: {}'.format(token.part_of_speech.tag, token.text_content))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def nlp_text(text):\n",
    "    print('================================================================================')\n",
    "    print('Text: {}'.format(text))\n",
    "    sentiment_text(text)\n",
    "    entities_text(text)\n",
    "    print('=========================================================')\n",
    "    syntax_text(text)\n",
    "\n",
    "    \n",
    "def nlp_gcs(bucket_name, source_blob_name):\n",
    "    gcs_uri = 'gs://' + bucket_name + '/' + source_blob_name\n",
    "    print('================================================================================')\n",
    "    print('Text: {}'.format(read_gcs(bucket_name, source_blob_name)))\n",
    "    sentiment_gcs(gcs_uri)\n",
    "    entities_gcs(gcs_uri)\n",
    "    print('=========================================================')\n",
    "    syntax_gcs(gcs_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Text: Hello, world!\n",
      "Score: 0.4\n",
      "Magnitude: 0.4\n",
      "====================\n",
      "name            : world\n",
      "type            : LOCATION\n",
      "metadata        : {}\n",
      "salience        : 1\n",
      "wikipedia_url   : -\n",
      "=========================================================\n",
      "X: Hello\n",
      "PUNCT: ,\n",
      "NOUN: world\n",
      "PUNCT: !\n",
      "================================================================================\n",
      "Text: President Obama is speaking at the White House.\n",
      "Score: 0.2\n",
      "Magnitude: 0.2\n",
      "====================\n",
      "name            : Obama\n",
      "type            : PERSON\n",
      "metadata        : {'wikipedia_url': 'http://en.wikipedia.org/wiki/Barack_Obama', 'mid': '/m/02mjmr'}\n",
      "salience        : 0.9077594\n",
      "wikipedia_url   : http://en.wikipedia.org/wiki/Barack_Obama\n",
      "====================\n",
      "name            : White House\n",
      "type            : LOCATION\n",
      "metadata        : {'wikipedia_url': 'http://en.wikipedia.org/wiki/White_House', 'mid': '/m/081sq'}\n",
      "salience        : 0.092240565\n",
      "wikipedia_url   : http://en.wikipedia.org/wiki/White_House\n",
      "=========================================================\n",
      "NOUN: President\n",
      "NOUN: Obama\n",
      "VERB: is\n",
      "VERB: speaking\n",
      "ADP: at\n",
      "DET: the\n",
      "NOUN: White\n",
      "NOUN: House\n",
      "PUNCT: .\n",
      "================================================================================\n",
      "Text: Ladies and gentlemen!\n",
      "Score: 0.3\n",
      "Magnitude: 0.3\n",
      "====================\n",
      "name            : Ladies\n",
      "type            : PERSON\n",
      "metadata        : {}\n",
      "salience        : 0.72030365\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : gentlemen\n",
      "type            : PERSON\n",
      "metadata        : {}\n",
      "salience        : 0.27969635\n",
      "wikipedia_url   : -\n",
      "=========================================================\n",
      "NOUN: Ladies\n",
      "CONJ: and\n",
      "NOUN: gentlemen\n",
      "PUNCT: !\n",
      "================================================================================\n",
      "Text: 世界、こんにちは！\n",
      "Score: 0.4\n",
      "Magnitude: 0.4\n",
      "====================\n",
      "name            : 世界\n",
      "type            : LOCATION\n",
      "metadata        : {}\n",
      "salience        : 1\n",
      "wikipedia_url   : -\n",
      "=========================================================\n",
      "NOUN: 世界\n",
      "PUNCT: 、\n",
      "NOUN: こんにちは\n",
      "PUNCT: ！\n",
      "================================================================================\n",
      "Text: 今日は天気いいですね！\n",
      "Score: 0.6\n",
      "Magnitude: 0.6\n",
      "====================\n",
      "name            : 天気\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 1\n",
      "wikipedia_url   : -\n",
      "=========================================================\n",
      "NOUN: 今日\n",
      "PRT: は\n",
      "NOUN: 天気\n",
      "ADJ: いい\n",
      "VERB: です\n",
      "PRT: ね\n",
      "PUNCT: ！\n",
      "================================================================================\n",
      "Text: 悲しいニュースですね\n",
      "Score: 0.1\n",
      "Magnitude: 0.1\n",
      "====================\n",
      "name            : ニュース\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 1\n",
      "wikipedia_url   : -\n",
      "=========================================================\n",
      "ADJ: 悲しい\n",
      "NOUN: ニュース\n",
      "VERB: です\n",
      "PRT: ね\n",
      "================================================================================\n",
      "Text: 素晴らしい\n",
      "Score: 0.8\n",
      "Magnitude: 0.8\n",
      "=========================================================\n",
      "ADJ: 素晴らしい\n",
      "================================================================================\n",
      "Text: Google Cloud Natural Language API は、使いやすい REST API を介して強力な機械学習モデルを提供することで、テキストの構造と意味を解析できるようにします。この API を使用すれば、ドキュメント、ニュース記事、ブログ記事に含まれる人、場所、イベントなどに関する情報を抽出できるようになります。ソーシャル メディア上のコメントから商品に対するセンチメント（感情）を把握したり、コールセンターやメッセージ アプリに寄せられた消費者の意見から顧客満足度を分析したりすることができます。リクエストでアップロードしたテキストを分析することも、Google Cloud Storage のドキュメント ストレージ上のデータを分析することもできます。\n",
      "Score: 0.2\n",
      "Magnitude: 1.2\n",
      "====================\n",
      "name            : テキスト\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.11724512\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : REST API\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.11026648\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : Google Cloud Natural Language API\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.11026648\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : こと\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.0692684\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 機械学習モデル\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.05191978\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 構造\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.05191978\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 意味\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.05191978\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : ドキュメント\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.040119454\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : API\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.034435473\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : ニュース記事\n",
      "type            : WORK_OF_ART\n",
      "metadata        : {}\n",
      "salience        : 0.027493568\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : ブログ記事\n",
      "type            : WORK_OF_ART\n",
      "metadata        : {}\n",
      "salience        : 0.027493568\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : ソーシャル メディア\n",
      "type            : ORGANIZATION\n",
      "metadata        : {}\n",
      "salience        : 0.025816482\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : イベント\n",
      "type            : EVENT\n",
      "metadata        : {}\n",
      "salience        : 0.021866148\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 情報\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.021866148\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 人\n",
      "type            : PERSON\n",
      "metadata        : {}\n",
      "salience        : 0.021866148\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 場所\n",
      "type            : LOCATION\n",
      "metadata        : {}\n",
      "salience        : 0.021866148\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : メッセージ アプリ\n",
      "type            : CONSUMER_GOOD\n",
      "metadata        : {}\n",
      "salience        : 0.021389212\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : センチメント\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.017440522\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : こと\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.017062293\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 消費者\n",
      "type            : PERSON\n",
      "metadata        : {}\n",
      "salience        : 0.015380931\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 意見\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.015380931\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 顧客満足度\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.015380931\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : コメント\n",
      "type            : WORK_OF_ART\n",
      "metadata        : {}\n",
      "salience        : 0.013776257\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : Google Cloud Storage\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.012656792\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : リクエスト\n",
      "type            : EVENT\n",
      "metadata        : {}\n",
      "salience        : 0.012224577\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : コールセンター\n",
      "type            : LOCATION\n",
      "metadata        : {}\n",
      "salience        : 0.011830591\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : ドキュメント ストレージ\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.011081101\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : データ\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.011081101\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 商品\n",
      "type            : CONSUMER_GOOD\n",
      "metadata        : {}\n",
      "salience        : 0.009842899\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 感情\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.009842899\n",
      "wikipedia_url   : -\n",
      "=========================================================\n",
      "NOUN: Google\n",
      "NOUN: Cloud\n",
      "X: Natural\n",
      "NOUN: Language\n",
      "NOUN: API\n",
      "PRT: は\n",
      "PUNCT: 、\n",
      "VERB: 使い\n",
      "ADJ: やすい\n",
      "NOUN: REST\n",
      "NOUN: API\n",
      "PRT: を\n",
      "VERB: 介し\n",
      "PRT: て\n",
      "ADJ: 強力\n",
      "VERB: な\n",
      "NOUN: 機械\n",
      "NOUN: 学習\n",
      "NOUN: モデル\n",
      "PRT: を\n",
      "NOUN: 提供\n",
      "VERB: する\n",
      "NOUN: こと\n",
      "VERB: で\n",
      "PUNCT: 、\n",
      "NOUN: テキスト\n",
      "PRT: の\n",
      "NOUN: 構造\n",
      "PRT: と\n",
      "NOUN: 意味\n",
      "PRT: を\n",
      "NOUN: 解析\n",
      "VERB: できる\n",
      "NOUN: よう\n",
      "VERB: にし\n",
      "VERB: ます\n",
      "PUNCT: 。\n",
      "DET: この\n",
      "NOUN: API\n",
      "PRT: を\n",
      "NOUN: 使用\n",
      "VERB: すれ\n",
      "PRT: ば\n",
      "PUNCT: 、\n",
      "NOUN: ドキュメント\n",
      "PUNCT: 、\n",
      "NOUN: ニュース\n",
      "NOUN: 記事\n",
      "PUNCT: 、\n",
      "NOUN: ブログ\n",
      "NOUN: 記事\n",
      "PRT: に\n",
      "VERB: 含ま\n",
      "VERB: れる\n",
      "NOUN: 人\n",
      "PUNCT: 、\n",
      "NOUN: 場所\n",
      "PUNCT: 、\n",
      "NOUN: イベント\n",
      "PRT: など\n",
      "PRT: に関する\n",
      "NOUN: 情報\n",
      "PRT: を\n",
      "NOUN: 抽出\n",
      "VERB: できる\n",
      "NOUN: よう\n",
      "PRT: に\n",
      "VERB: なり\n",
      "VERB: ます\n",
      "PUNCT: 。\n",
      "NOUN: ソーシャル\n",
      "NOUN: メディア\n",
      "AFFIX: 上\n",
      "PRT: の\n",
      "NOUN: コメント\n",
      "PRT: から\n",
      "NOUN: 商品\n",
      "PRT: に対する\n",
      "NOUN: センチ\n",
      "NOUN: メント\n",
      "PUNCT: （\n",
      "NOUN: 感情\n",
      "PUNCT: ）\n",
      "PRT: を\n",
      "NOUN: 把握\n",
      "VERB: し\n",
      "PRT: たり\n",
      "PUNCT: 、\n",
      "NOUN: コールセンター\n",
      "PRT: や\n",
      "NOUN: メッセージ\n",
      "NOUN: アプリ\n",
      "PRT: に\n",
      "VERB: 寄せ\n",
      "VERB: られ\n",
      "VERB: た\n",
      "NOUN: 消費\n",
      "AFFIX: 者\n",
      "PRT: の\n",
      "NOUN: 意見\n",
      "PRT: から\n",
      "NOUN: 顧客\n",
      "NOUN: 満足\n",
      "AFFIX: 度\n",
      "PRT: を\n",
      "NOUN: 分析\n",
      "VERB: し\n",
      "PRT: たり\n",
      "VERB: する\n",
      "VERB: こと\n",
      "VERB: が\n",
      "VERB: でき\n",
      "VERB: ます\n",
      "PUNCT: 。\n",
      "NOUN: リクエスト\n",
      "PRT: で\n",
      "NOUN: アップロード\n",
      "NOUN: した\n",
      "NOUN: テキスト\n",
      "PRT: を\n",
      "NOUN: 分析\n",
      "VERB: する\n",
      "NOUN: こと\n",
      "PRT: も\n",
      "PUNCT: 、\n",
      "NOUN: Google\n",
      "NOUN: Cloud\n",
      "NOUN: Storage\n",
      "PRT: の\n",
      "NOUN: ドキュメント\n",
      "NOUN: ストレージ\n",
      "AFFIX: 上\n",
      "PRT: の\n",
      "NOUN: データ\n",
      "PRT: を\n",
      "NOUN: 分析\n",
      "VERB: する\n",
      "VERB: こと\n",
      "PRT: も\n",
      "VERB: でき\n",
      "VERB: ます\n",
      "PUNCT: 。\n",
      "NOUN: ＡＩ\n",
      "PRT: の\n",
      "NOUN: 経済\n",
      "NOUN: 効果\n",
      "PUNCT: 、\n",
      "NUM: 2030\n",
      "AFFIX: 年\n",
      "PRT: まで\n",
      "PRT: に\n",
      "NUM: 1780\n",
      "AFFIX: 兆\n",
      "AFFIX: 円\n",
      "ADJ: 規模\n"
     ]
    }
   ],
   "source": [
    "for text in texts.split('\\n'):\n",
    "    nlp_text(text)\n",
    "\n",
    "tokens = syntax_file(gcs_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Blob messages/-KoD6Ht5pST_rdxZTXkZ downloaded to /tmp/tmpp2rk7u01.\n",
      "Text: ＡＩの経済効果、2030年までに1780兆円規模\n",
      "Score: 0.3\n",
      "Magnitude: 0.3\n",
      "====================\n",
      "name            : AI\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.5231133\n",
      "wikipedia_url   : -\n",
      "====================\n",
      "name            : 経済効果\n",
      "type            : OTHER\n",
      "metadata        : {}\n",
      "salience        : 0.47688666\n",
      "wikipedia_url   : -\n",
      "=========================================================\n",
      "NOUN: ＡＩ\n",
      "PRT: の\n",
      "NOUN: 経済\n",
      "NOUN: 効果\n",
      "PUNCT: 、\n",
      "NUM: 2030\n",
      "AFFIX: 年\n",
      "PRT: まで\n",
      "PRT: に\n",
      "NUM: 1780\n",
      "AFFIX: 兆\n",
      "AFFIX: 円\n",
      "ADJ: 規模\n"
     ]
    }
   ],
   "source": [
    "nlp_gcs('qa-nlp-1.appspot.com', 'messages/-KoD6Ht5pST_rdxZTXkZ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
